{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5FVk1lPvEvmO"
      },
      "outputs": [],
      "source": [
        "# importing the required libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import imageio\n",
        "import imgaug as ia\n",
        "import imgaug.augmenters as iaa\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "from PIL import Image\n",
        "import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import datasets, models, transforms\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import random_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCmt5XgxtEy1",
        "outputId": "8d26ec3b-611c-43c0-d097-5d83ca3c5d91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.17.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: torch==2.2.1 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.2.1+cu121)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.1->torchvision)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.1->torchvision)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.1->torchvision)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.1->torchvision)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install torch\n",
        "!pip install torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-EZDBjkLsa4r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e02a28b5-311e-4eb4-cae4-87a5bffd3e80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UIaedKmVE5b8"
      },
      "outputs": [],
      "source": [
        "input_path = \"/content/drive/MyDrive/Dataset0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxi88R7LE58J"
      },
      "outputs": [],
      "source": [
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YjjuCZGME8B-"
      },
      "outputs": [],
      "source": [
        "data_transforms = {\n",
        "    'Dataset0':\n",
        "    transforms.Compose([\n",
        "        transforms.Resize((224,224)),\n",
        "        #Dataaugmentation\n",
        "        #transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n",
        "        ##transforms.RandomRotation(10),\n",
        "        ##transforms.RandomErasing(scale=(0.02, 0.16), ratio=(0.3, 1.6)),\n",
        "        #transforms.RandomPerspective(distortion_scale=0.2),\n",
        "        #transforms.RandomHorizontalFlip(),\n",
        "        ##transforms.CenterCrop(10),\n",
        "        transforms.ToTensor(),\n",
        "        normalize\n",
        "    ]),\n",
        "    #'TE_PARKTRAIN':\n",
        "    #transforms.Compose([\n",
        "    #    transforms.Resize((224,224)),\n",
        "    #    transforms.ToTensor(),\n",
        "    #    normalize\n",
        "    #]),\n",
        "}\n",
        "image_datasets = {\n",
        "    'Dataset0':\n",
        "    datasets.ImageFolder(input_path + '', data_transforms['Dataset0']),\n",
        "    #'TE_PARKTRAIN':\n",
        "    #datasets.ImageFolder(input_path + 'TE_PARKTRAIN', data_transforms['TE_PARKTRAIN'])\n",
        "}\n",
        "\n",
        "# Define the ratio for splitting the data (e.g., 80% for training, 20% for testing)\n",
        "train_ratio = 0.8\n",
        "test_ratio = 1 - train_ratio\n",
        "\n",
        "# Split the datasets into training and testing sets\n",
        "train_size_A = int(train_ratio * len(image_datasets['Dataset0']))\n",
        "test_size_A = len(image_datasets['Dataset0']) - train_size_A\n",
        "\n",
        "train_dataset_A, test_dataset_A = random_split(image_datasets['Dataset0'], [train_size_A, test_size_A])\n",
        "\n",
        "train_dataloader_A = torch.utils.data.DataLoader(train_dataset_A, batch_size=5, shuffle=True, num_workers=0)\n",
        "test_dataloader_A = torch.utils.data.DataLoader(test_dataset_A, batch_size=5, shuffle=False, num_workers=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "427SyUVNFAyy"
      },
      "outputs": [],
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfSu8fjfFEcm",
        "outputId": "0693e5b9-59b4-4e8f-ab6a-3bb81a58349c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n",
            "100%|██████████| 13.6M/13.6M [00:00<00:00, 119MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MobileNetV2(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2dNormActivation(\n",
            "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU6(inplace=True)\n",
            "    )\n",
            "    (1): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (2): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
            "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (3): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
            "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (4): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
            "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (5): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
            "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (6): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
            "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (7): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
            "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (8): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
            "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (9): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
            "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (10): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
            "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (11): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
            "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (12): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
            "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (13): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
            "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (14): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
            "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (15): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
            "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (16): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
            "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (17): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
            "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (18): Conv2dNormActivation(\n",
            "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU6(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.2, inplace=False)\n",
            "    (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n",
            "MobileNetV2(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2dNormActivation(\n",
            "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU6(inplace=True)\n",
            "    )\n",
            "    (1): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (2): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
            "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (3): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
            "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (4): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
            "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (5): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
            "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (6): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
            "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (7): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
            "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (8): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
            "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (9): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
            "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (10): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
            "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (11): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
            "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (12): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
            "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (13): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
            "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (14): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
            "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (15): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
            "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (16): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
            "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (17): InvertedResidual(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
            "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (18): Conv2dNormActivation(\n",
            "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU6(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.2, inplace=False)\n",
            "    (1): Linear(in_features=1280, out_features=2, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "#model = models.inception_v3(pretrained=True).to(device)\n",
        "#model.fc = nn.Linear(in_features=2048, out_features=2, bias=True).to(device) #adapt last layer\n",
        "#model.fc = nn.Linear(in_features=2048, out_features=2, bias=True).to(device) #adapt last layer\n",
        "model = models.mobilenet_v2(pretrained=True)\n",
        "print(model)\n",
        "model.classifier = torch.nn.Sequential(\n",
        "    torch.nn.Dropout(p=0.2, inplace=False),\n",
        "    torch.nn.Linear(1280, 2)\n",
        ")\n",
        "model = model.to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1O1gh4BwFGZU"
      },
      "outputs": [],
      "source": [
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.005, weight_decay = 0.005, momentum = 0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "I5c4Ri8zFJm9",
        "outputId": "c1f25d26-63f5-46ea-b88b-9f40786bce2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/50], Step [862], Loss: 0.6941\n",
            "Accuracy of the network on the validation images: 52.319109461966605 %\n"
          ]
        },
        {
          "ename": "ZeroDivisionError",
          "evalue": "division by zero",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-78682e58ccc4>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy of the network on the validation images: {} %'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m# Calculate precision, recall, and F1 score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtp\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mrecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtp\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprecision\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprecision\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
          ]
        }
      ],
      "source": [
        "corrects=0\n",
        "num_epochs=50\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_dataloader_A):\n",
        "        # Move tensors to the configured device\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        #outputs= outputs.logits\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print ('Epoch [{}/{}], Step [{}], Loss: {:.4f}'\n",
        "                   .format(epoch+1, num_epochs, i+1, loss.item()))\n",
        "    tp = 0\n",
        "    fp = 0\n",
        "    fn = 0\n",
        "    # Validation\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in test_dataloader_A:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            tp += ((predicted == labels) & (predicted == 1)).sum().item()\n",
        "            fp += ((predicted != labels) & (predicted == 1)).sum().item()\n",
        "            fn += ((predicted != labels) & (predicted == 0)).sum().item()\n",
        "\n",
        "            del images, labels, outputs\n",
        "\n",
        "        print('Accuracy of the network on the validation images: {} %'.format(100 * correct / total))\n",
        "        # Calculate precision, recall, and F1 score\n",
        "        precision = tp / (tp + fp)\n",
        "        recall = tp / (tp + fn)\n",
        "        f1 = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "        print('Precision: {:.4f}'.format(precision))\n",
        "        print('Recall: {:.4f}'.format(recall))\n",
        "        print('F1 Score: {:.4f}'.format(f1))\n",
        "    if corrects<=correct:\n",
        "      corrects=correct\n",
        "      torch.save(model.state_dict(), '/content/drive/MyDrive/models0/CNN.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOnUAfSjBwOn"
      },
      "source": [
        "Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0m7h38oDByOf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d38ea6d-416f-47f5-e52b-c17094fe8fca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n",
            "100%|██████████| 13.6M/13.6M [00:00<00:00, 54.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.21662383 0.21546754 0.22965686 ... 0.09036835 0.15718202 0.18949118]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "from PIL import Image\n",
        "\n",
        "# Preprocess images\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Load the pre-trained MobileNetV2 model\n",
        "model = models.mobilenet_v2(pretrained=True)\n",
        "model.classifier = torch.nn.Sequential(\n",
        "    torch.nn.Dropout(p=0.2, inplace=False),\n",
        "    torch.nn.Linear(1280, 2)\n",
        ")\n",
        "# Load the saved model weights\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/models0/CNN.h5\", map_location=torch.device('cpu')))\n",
        "\n",
        "# Use the features before the classifier layer to extract embeddings\n",
        "layer = model.features\n",
        "\n",
        "# Define the function to get feature vectors\n",
        "def get_vector(image_path):\n",
        "    # Load and preprocess the image\n",
        "    image = Image.open(image_path)\n",
        "    image = preprocess(image).unsqueeze(0)\n",
        "\n",
        "    # Create a tensor to store the features\n",
        "    my_embedding = torch.zeros(1280)\n",
        "\n",
        "    # Define a function to copy the output of the layer\n",
        "    def copy_data(m, i, o):\n",
        "        my_embedding.copy_(torch.mean(o.squeeze(), dim=[1,2])) # Global Average Pooling\n",
        "\n",
        "    # Attach the copy function to the selected layer\n",
        "    h = layer.register_forward_hook(copy_data)\n",
        "\n",
        "    # Pass the image through the model\n",
        "    with torch.no_grad():\n",
        "        model(image)\n",
        "\n",
        "    # Detach the copy function from the layer\n",
        "    h.remove()\n",
        "\n",
        "    # Return the feature vector\n",
        "    return my_embedding\n",
        "\n",
        "# Test the get_vector function with an image path\n",
        "image_path = \"/content/drive/MyDrive/EssentialTremorProject/Normal/patient32/0-crops/32-tes-0-1-R-crops/1.jpg\"\n",
        "vector = get_vector(image_path)\n",
        "print(vector.numpy())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import os\n",
        "\n",
        "# Définir le chemin pour enregistrer les vecteurs dans le fichier CSV\n",
        "output_vectors_Train = \"/content/drive/MyDrive/Data0/vecteursTrain.csv\"\n",
        "\n",
        "# Définir le chemin pour enregistrer les labels dans le fichier CSV\n",
        "output_labels_Train = \"/content/drive/MyDrive/Data0/labelsTrain.csv\"\n",
        "\n",
        "with open(output_vectors_Train, 'w', newline='') as vectors_csvfile, open(output_labels_Train, 'w', newline='') as labels_csvfile:\n",
        "    vectors_writer = csv.writer(vectors_csvfile)\n",
        "    labels_writer = csv.writer(labels_csvfile)\n",
        "\n",
        "    for class_dir in [\"Healthy0\", \"TE0\"]:\n",
        "        listPatient = os.listdir(\"/content/drive/MyDrive/PFA/\"+class_dir+\"/0\")\n",
        "\n",
        "        for patient in listPatient:\n",
        "            listVideos = os.listdir(\"/content/drive/MyDrive/PFA/\"+class_dir+\"/0/\"+patient)\n",
        "            if (class_dir == 'Healthy0' and patient == '77') or (class_dir == 'TE0' and patient == '36'):\n",
        "                exit()\n",
        "            else:\n",
        "                listVideost = os.listdir(\"/content/drive/MyDrive/PFA/\"+class_dir+\"/0/\"+patient)\n",
        "\n",
        "                for video in listVideos:\n",
        "                    if os.path.isdir(\"/content/drive/MyDrive/PFA/\"+class_dir+\"/0/\"+patient+\"/\"+video):\n",
        "                        if os.path.exists(\"/content/drive/MyDrive/PFA/\"+class_dir+\"/0/\"+patient+\"/\"+video+\"/\"):\n",
        "                            path = \"/content/drive/MyDrive/PFA/\"+class_dir+\"/0/\"+patient+\"/\"+video+\"/\"\n",
        "                        else:\n",
        "                            path = \"/content/drive/MyDrive/PFA/\"+class_dir+\"/0/\"+patient+\"/\"+video+\"/\"\n",
        "\n",
        "                        listFrames = os.listdir(path)\n",
        "\n",
        "                        i = 9\n",
        "                        nbrFrame = 0\n",
        "\n",
        "                        for frame in listFrames:\n",
        "                            if i % 2 == 0 and nbrFrame < 25:\n",
        "                                nbrFrame += 1\n",
        "                                vector = get_vector(path + frame)\n",
        "                                vectors_writer.writerow(vector.numpy())\n",
        "\n",
        "                                if class_dir == \"Healthy0\":\n",
        "                                    labels_writer.writerow([0])\n",
        "                                elif class_dir == \"TE0\":\n",
        "                                    labels_writer.writerow([1])\n",
        "\n",
        "                            i += 1\n"
      ],
      "metadata": {
        "id": "LMafQhbLRpGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "listPatient = os.listdir(\"/content/drive/MyDrive/PFA/Healthy/90\")\n",
        "listPatient"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zeApXRN4Prb",
        "outputId": "acd09c0f-8812-4bd0-b076-72196bfbfb49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['23',\n",
              " '02',\n",
              " '82',\n",
              " '81',\n",
              " '80',\n",
              " '79',\n",
              " '78',\n",
              " '77',\n",
              " '76',\n",
              " '75',\n",
              " '74',\n",
              " '73',\n",
              " '69',\n",
              " '68',\n",
              " '63',\n",
              " '59',\n",
              " '58 (1)',\n",
              " '58',\n",
              " '57',\n",
              " '56',\n",
              " '55',\n",
              " '54']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "listPatient = os.listdir(\"/content/drive/MyDrive/PFA/TE0/0\")\n",
        "listPatient"
      ],
      "metadata": {
        "id": "lxVXhZIE4vfV",
        "outputId": "65f36d75-3e3a-4775-8c96-7af85e5f0365",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['00',\n",
              " '31',\n",
              " '07',\n",
              " '08',\n",
              " '12',\n",
              " '09',\n",
              " '14',\n",
              " '15',\n",
              " '16',\n",
              " '18',\n",
              " '20',\n",
              " '23',\n",
              " '24',\n",
              " '30',\n",
              " '32',\n",
              " '35',\n",
              " '36',\n",
              " '41',\n",
              " '42',\n",
              " '114',\n",
              " '115',\n",
              " '139']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "# Définir le chemin pour enregistrer les vecteurs dans le fichier CSV\n",
        "output_vectors_Train = \"/content/drive/MyDrive/Data0/vecteursTest.csv\"\n",
        "\n",
        "# Définir le chemin pour enregistrer les labels dans le fichier CSV\n",
        "output_labels_Train = \"/content/drive/MyDrive/Data0/labelsTest.csv\"\n",
        "with open(output_vectors_Train, 'w', newline='') as vectors_csvfile, open(output_labels_Train, 'w', newline='') as labels_csvfile:\n",
        "  vectors_writer = csv.writer(vectors_csvfile)\n",
        "  labels_writer = csv.writer(labels_csvfile)\n",
        "  for class_dir in [\"Healthy0\", \"TE0\"]:\n",
        "    listPatient=os.listdir(\"/content/drive/MyDrive/PFA/\"+class_dir+\"/0\")\n",
        "    print(listPatient)\n",
        "    for patient in listPatient:\n",
        "      if (class_dir== 'Healthy0' and (patient == '58' or patient == '57' or patient == '56' or patient == '55' or patient == '54')) or (class_dir== 'TE0' and (patient == '41' or patient == '42' or patient == '114' or patient == '115' or patient == '139')):\n",
        "        listVideost=os.listdir(\"/content/drive/MyDrive/PFA/\"+class_dir+\"/0/\"+patient)\n",
        "        print(listVideost)\n",
        "        for video in listVideost:\n",
        "          os.listdir(\"/content/drive/MyDrive/PFA/\"+class_dir+\"/0/\"+patient+\"/\"+video)\n",
        "          listframes=os.listdir(\"/content/drive/MyDrive/PFA/\"+class_dir+\"/0/\"+patient+\"/\"+video)\n",
        "          path=\"/content/drive/MyDrive/PFA/\"+class_dir+\"/0/\"+patient+\"/\"+video+\"/\"\n",
        "        else:\n",
        "\n",
        "          listframes=os.listdir(\"/content/drive/MyDrive/PFA/\"+class_dir+\"/0/\"+patient+\"/\"+video)\n",
        "          path=\"/content/drive/MyDrive/PFA/\"+class_dir+\"/0/\"+patient+\"/\"+video\n",
        "          i=9\n",
        "          nbrFrame=0\n",
        "\n",
        "          for frame in listframes:\n",
        "            i=i+1\n",
        "            if i%2==0 and nbrFrame<25:\n",
        "              nbrFrame=nbrFrame+1\n",
        "              vector=get_vector(path+\"/\"+frame)\n",
        "              # Écrire le vecteur dans le fichier CSV des vecteurs\n",
        "              vectors_writer.writerow(vector.numpy())\n",
        "              # Écrire le label dans le fichier CSV des labels\n",
        "              if class_dir== \"Healthy0\":\n",
        "                labels_writer.writerow([0])\n",
        "              if class_dir==\"TE0\":\n",
        "                labels_writer.writerow([1])"
      ],
      "metadata": {
        "id": "gkBi4-fvgOZ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4aff3ba5-641f-418c-f42f-8c77b59a0ec7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['23', '02', '82', '81', '80', '79', '78', '77', '76', '75', '74', '73', '69', '68', '63', '59', '58 (1)', '58', '57', '56', '55', '54']\n",
            "['58T-0-11-R-crops', '58T-0-2-L-crops', '58T-0-10-R-crops', '58T-0-6-R-crops', '58T-0-5-L-crops', '58T-0-9-R-crops', '58T-0-4-L-crops', '58T-0-8-R-crops', '58T-0-3-L-crops', '58T-0-7-R-crops', '58T-0-1-L-crops']\n",
            "['57T-0-8-R-crops', '57T-0-5-L-crops', '57T-0-4-L-crops', '57T-0-11-R-crops', '57T-0-9-R-crops', '57T-0-10-R-crops', '57T-0-6-L-crops', '57T-0-3-L-crops', '57T-0-7-R-crops', '57T-0-12-R-crops', '57T-0-1-L-crops', '57T-0-2-L-crops']\n",
            "['56T-0-3-L-crops', '56T-0-5-L-crops', '56T-0-10-R-crops', '56T-0-12-R-crops', '56T-0-8-R-crops', '56T-0-9-R-crops', '56T-0-7-R-crops', '56T-0-6-L-crops', '56T-0-11-R-crops', '56T-0-4-L-crops', '56T-0-1-L-crops', '56T-0-2-L-crops']\n",
            "['55T-0-9-R-crops', '55T-0-8-R-crops', '55T-0-11-R-crops', '55T-0-10-R-crops', '55T-0-3-L-crops', '55T-0-7-R-crops', '55T-0-4-L-crops', '55T-0-6-L-crops', '55T-0-12-R-crops', '55T-0-5-L-crops', '55T-0-1-L-crops', '55T-0-2-L-crops']\n",
            "['54T-0-2-L-crops', '54T-0-6-L-crops', '54T-0-3-L-crops', '54T-0-9-R-crops', '54T-0-8-R-crops', '54T-0-4-L-crops', '54T-0-11-R-crops', '54T-0-5-L-crops', '54T-0-7-R-crops', '54T-0-10-R-crops', '54T-0-1-L-crops']\n",
            "['00', '31', '07', '08', '12', '09', '14', '15', '16', '18', '20', '23', '24', '30', '32', '35', '36', '41', '42', '114', '115', '139']\n",
            "['41-tes-0-10-L-crops', '41-tes-0-7-L-crops', '41-tes-0-2-R-crops', '41-tes-0-4-R-crops', '41-tes-0-8-L-crops', '41-tes-0-5-R-crops', '41-tes-0-9-L-crops', '41-tes-0-3-R-crops', '41-tes-0-6-R-crops', '41-tes-0-1-R-crops', '41-tes-0-12-L-crops', '41-tes-0-11-L-crops']\n",
            "['42-tes-0-7-L-crops', '42-tes-0-10-L-crops', '42-tes-0-8-L-crops', '42-tes-0-1-R-crops', '42-tes-0-9-L-crops', '42-tes-0-4-R-crops', '42-tes-0-6-L-crops', '42-tes-0-2-R-crops', '42-tes-0-3-R-crops', '42-tes-0-5-R-crops', '42-tes-0-11-L-crops']\n",
            "['14-tes-0-4-L-crops', '14-tes-0-3-R-crops', '14-tes-0-5-L-crops', '14-tes-0-6-L-crops', '14-tes-0-1-R-crops', '14-tes-0-2-R-crops']\n",
            "['15-tes-0-7-R-crops', '15-tes-0-1-R-crops', '15-tes-0-9-R-crops', '15-tes-0-10-R-crops', '15-tes-0-2-R-crops', '15-tes-0-5-R-crops', '15-tes-0-3-R-crops', '15-tes-0-6-R-crops', '15-tes-0-8-R-crops', '15-tes-0-4-R-crops', '15-tes-0-16-L-crops', '15-tes-0-13-L-crops', '15-tes-0-11-R-crops', '15-tes-0-14-L-crops', '15-tes-0-15-L-crops', '15-tes-0-12-L-crops']\n",
            "['139-tes-0-4-R-crops', '139-tes-0-5-R-crops', '139-tes-0-2-R-crops', '139-tes-0-3-R-crops', '139-tes-0-1-R-crops', '139-tes-0-6-R-crops']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LSTM**"
      ],
      "metadata": {
        "id": "FvP8z63ibizs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "difR9OyyBzX8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d202089f-e917-44cc-c7ac-9ac467957e20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data dimensions: 395, (395, 1)\n",
            "Test data dimensions: (10, 25, 1280), (10, 1)\n",
            "layers=[256, 128, 64, 1], train_examples=395, test_examples=10\n",
            "batch = 395, timesteps = 25, features = 1280, epochs = 100\n",
            "lr = 0.05, lambda = 0.03, dropout = 0.0, recurr_dropout = 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 25, 256)           1573888   \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 25, 256)           1024      \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 25, 128)           197120    \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 25, 128)           512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 64)                49408     \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 64)                256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1822273 (6.95 MB)\n",
            "Trainable params: 1821377 (6.95 MB)\n",
            "Non-trainable params: 896 (3.50 KB)\n",
            "_________________________________________________________________\n",
            "None\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "Epoch 31: early stopping\n",
            "-----------------------------------------------------------------\n",
            "Training was completed in 17.13 secs\n",
            "-----------------------------------------------------------------\n",
            "-----------------------------------------------------------------\n",
            "train accuracy = 98.481%\n",
            "test accuracy = 90.0%\n",
            "test error = 1 out of 10 examples\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from numpy import genfromtxt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, BatchNormalization\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from keras.regularizers import l2\n",
        "from time import time\n",
        "\n",
        "def convert_to_floats(arr):\n",
        "    result = map(float, arr)\n",
        "    return list(result)\n",
        "\n",
        "dataTraining = genfromtxt(\"/content/drive/MyDrive/Data0/vecteursTrain.csv\", delimiter=',', dtype=float)\n",
        "LabelTraining = genfromtxt(\"/content/drive/MyDrive/Data0/labelsTrain.csv\", delimiter=',', dtype=float)\n",
        "dataTesting = genfromtxt(\"/content/drive/MyDrive/Data0/vecteursTest.csv\", delimiter=',', dtype=float)\n",
        "Labelcsv_testLabels = genfromtxt(\"/content/drive/MyDrive/Data0/labelsTest.csv\", delimiter=',', dtype=float)\n",
        "\n",
        "scaled_train_features = dataTraining\n",
        "train_labels = LabelTraining\n",
        "T = 25\n",
        "\n",
        "X_train, y_train = [], []\n",
        "for i in range(0, train_labels.shape[0], 25):\n",
        "    X_train.append(scaled_train_features[i:i+T])\n",
        "    y_train.append(train_labels[i])\n",
        "\n",
        "max_length = max(len(seq) for seq in X_train)\n",
        "X_train_padded = np.array([np.pad(seq, ((0, max_length - len(seq)), (0, 0)), mode='constant') for seq in X_train])\n",
        "\n",
        "y_train = np.array(y_train).reshape(-1, 1)\n",
        "print(f'Train data dimensions: {len(X_train_padded)}, {y_train.shape}')\n",
        "\n",
        "test_labels = Labelcsv_testLabels\n",
        "scaled_test_features = dataTesting\n",
        "\n",
        "X_test, y_test = [], []\n",
        "for i in range(0, test_labels.shape[0], 25):\n",
        "    X_test.append(scaled_test_features[i:i+T])\n",
        "    y_test.append(test_labels[i])\n",
        "\n",
        "X_test_padded = np.array([np.pad(seq, ((0, max_length - len(seq)), (0, 0)), mode='constant') for seq in X_test])\n",
        "y_test = np.array(y_test).reshape(-1, 1)\n",
        "print(f'Test data dimensions: {X_test_padded.shape}, {y_test.shape}')\n",
        "\n",
        "LAYERS = [256, 128, 64, 1]\n",
        "M_TRAIN = X_train_padded.shape[0]\n",
        "M_TEST = X_test_padded.shape[0]\n",
        "N = X_train_padded.shape[2]\n",
        "BATCH = M_TRAIN\n",
        "EPOCH = 100\n",
        "LR = 5e-2\n",
        "LAMBD = 3e-2\n",
        "DP = 0.0\n",
        "RDP = 0.0\n",
        "\n",
        "print(f'layers={LAYERS}, train_examples={M_TRAIN}, test_examples={M_TEST}')\n",
        "print(f'batch = {BATCH}, timesteps = {T}, features = {N}, epochs = {EPOCH}')\n",
        "print(f'lr = {LR}, lambda = {LAMBD}, dropout = {DP}, recurr_dropout = {RDP}')\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(input_shape=(max_length, N), units=LAYERS[0],\n",
        "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
        "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
        "               dropout=DP, recurrent_dropout=RDP,\n",
        "               return_sequences=True, return_state=False,\n",
        "               stateful=False, unroll=False\n",
        "              ))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LSTM(units=LAYERS[1],\n",
        "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
        "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
        "               dropout=DP, recurrent_dropout=RDP,\n",
        "               return_sequences=True, return_state=False,\n",
        "               stateful=False, unroll=False\n",
        "              ))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LSTM(units=LAYERS[2],\n",
        "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
        "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
        "               dropout=DP, recurrent_dropout=RDP,\n",
        "               return_sequences=False, return_state=False,\n",
        "               stateful=False, unroll=False\n",
        "              ))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(units=LAYERS[3], activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              metrics=['accuracy'],\n",
        "              optimizer=Adam(learning_rate=LR))\n",
        "print(model.summary())\n",
        "\n",
        "lr_decay = ReduceLROnPlateau(monitor='loss',\n",
        "                             patience=1, verbose=0,\n",
        "                             factor=0.5, min_lr=1e-8)\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_accuracy', min_delta=0,\n",
        "                           patience=30, verbose=1, mode='auto',\n",
        "                           baseline=0, restore_best_weights=True)\n",
        "\n",
        "start = time()\n",
        "History = model.fit(X_train_padded, y_train,\n",
        "                    epochs=EPOCH,\n",
        "                    batch_size=BATCH,\n",
        "                    validation_split=0.0,\n",
        "                    validation_data=(X_test_padded[:M_TEST], y_test[:M_TEST]),\n",
        "                    shuffle=True,verbose=0,\n",
        "                    callbacks=[lr_decay, early_stop])\n",
        "print('-'*65)\n",
        "print(f'Training was completed in {time() - start:.2f} secs')\n",
        "print('-'*65)\n",
        "\n",
        "train_loss, train_acc = model.evaluate(X_train_padded, y_train,\n",
        "                                       batch_size=M_TRAIN, verbose=0)\n",
        "test_loss, test_acc = model.evaluate(X_test_padded[:M_TEST], y_test[:M_TEST],\n",
        "                                     batch_size=M_TEST, verbose=0)\n",
        "print('-'*65)\n",
        "print(f'train accuracy = {round(train_acc * 100, 4)}%')\n",
        "print(f'test accuracy = {round(test_acc * 100, 4)}%')\n",
        "print(f'test error = {round((1 - test_acc) * M_TEST)} out of {M_TEST} examples')\n",
        "\n",
        "# Calculate precision, recall, and F1-score on the test set\n",
        "y_pred = model.predict(X_test_padded[:M_TEST])\n",
        "y_pred_binary = (y_pred > 0.5).astype(int)  # Convert probabilities to binary predictions\n",
        "\n",
        "precision = precision_score(y_test[:M_TEST], y_pred_binary)\n",
        "recall = recall_score(y_test[:M_TEST], y_pred_binary)\n",
        "f1 = f1_score(y_test[:M_TEST], y_pred_binary)\n",
        "\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1-score: {f1}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F8wHvLfRkrr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tester une vidèo"
      ],
      "metadata": {
        "id": "B-m_aaNbYfHf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import os\n",
        "\n",
        "# Définir le chemin pour enregistrer les vecteurs dans le fichier CSV\n",
        "output_vectors_Train = \"/content/drive/MyDrive/Data0/vecteursTest.csv\"\n",
        "output_labels_Train = \"/content/drive/MyDrive/Data0/labelsTest.csv\"  # Définir le chemin pour enregistrer les labels\n",
        "\n",
        "with open(output_vectors_Train, 'w', newline='') as vectors_csvfile, open(output_labels_Train, 'w', newline='') as labels_csvfile:\n",
        "    vectors_writer = csv.writer(vectors_csvfile)\n",
        "    # Votre code pour lire les images et écrire les vecteurs dans le fichier CSV\n",
        "\n",
        "\n",
        "\n",
        "    path = \"/content/drive/MyDrive/EssentialTremorProject/Normal/patient20/0-crops/20-tes-0-1-R-crops\"\n",
        "    listFrames = os.listdir(path)\n",
        "    i = 9\n",
        "    nbrFrame = 0\n",
        "    for frame in listFrames:\n",
        "      if i % 2 == 0 and nbrFrame < 25:\n",
        "        nbrFrame += 1\n",
        "        vector = get_vector(path +\"/\"+ frame)\n",
        "        vectors_writer.writerow(vector.numpy())\n",
        "      i += 1"
      ],
      "metadata": {
        "id": "bP0jUYBGYoIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5yWMafvbobb",
        "outputId": "7f66b0e7-389f-4c41-d629-e66d5828d962"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numpy import genfromtxt\n",
        "import torch\n",
        "from torchvision.models import mobilenet_v2\n",
        "from time import time\n",
        "\n",
        "# Charger les données de test à partir du fichier CSV\n",
        "dataTesting1 = genfromtxt(\"/content/drive/MyDrive/Data0/vecteursTest.csv\", delimiter=',', dtype=float)\n",
        "T = 25\n",
        "scaled_test_features1 = dataTesting1\n",
        "\n",
        "X_test1 = []\n",
        "for i in scaled_test_features1:\n",
        "    X_test1.append(i)\n",
        "\n",
        "# Remplir les données de test pour atteindre une longueur de 25 (si nécessaire)\n",
        "X_test_padded1 = np.array([np.pad(X_test1, ((0, 25 - len(X_test1)), (0, 0)), mode='constant')])\n",
        "\n",
        "# Ajouter deux canaux supplémentaires pour correspondre aux trois canaux attendus par MobileNetV2\n",
        "X_test_tensor = torch.tensor(X_test_padded1, dtype=torch.float32)\n",
        "X_test_tensor = X_test_tensor.unsqueeze(1).repeat(1, 3, 1, 1)\n",
        "\n",
        "# Charger le modèle PyTorch MobileNetV2 pré-entraîné\n",
        "model = mobilenet_v2(pretrained=True)\n",
        "\n",
        "# Mettre le modèle en mode évaluation\n",
        "model.eval()\n",
        "\n",
        "# Faire une prédiction avec le modèle\n",
        "with torch.no_grad():\n",
        "    y_pred_group1 = model(X_test_tensor)\n",
        "\n",
        "# Convertir les prédictions en classes binaires\n",
        "y_pred_binary_group = (y_pred_group1 > 0.5).int()\n",
        "classe = y_pred_binary_group[0][0].item()  # Convertir le tenseur en scalaire Python\n",
        "\n",
        "print(\"Classe de la vidéo :\", classe)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ut610DRwd5Lh",
        "outputId": "a3d1c294-f28e-45f0-ad0e-4c6604b7be8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classe de la vidéo : 0\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}